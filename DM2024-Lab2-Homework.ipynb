{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name: ç›§å­æ¶µ\n",
    "\n",
    "Student ID: 113065542\n",
    "\n",
    "GitHub ID: luzi2023\n",
    "\n",
    "Kaggle name: luzi8451\n",
    "\n",
    "Kaggle private scoreboard snapshot: ![pic0.png](attachment:\"img/pic0.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "image/png": {
       "height": 600,
       "width": 850
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "PATH = \"img/pic0.png\"\n",
    "Image(filename = PATH , width=850, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home exercises** in the [DM2024-Lab2-master Repo](https://github.com/didiersalazar/DM2024-Lab2-Master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework) regarding Emotion Recognition on Twitter by this link: https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
    "    Submit your last submission **BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)**. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developing the model for the competition (You can use code and comment on it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### =======================First Part================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# train_df\n",
    "train_all_words = []\n",
    "for text in train_df['text']:\n",
    "    train_all_words.extend(word_tokenize(text.lower()))\n",
    "    \n",
    "train_word_freq = Counter(train_all_words)\n",
    "    \n",
    "train_most_common = train_word_freq.most_common(30)\n",
    "words, counts = zip(*train_most_common)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "sns.barplot(x=list(counts), y=list(words), ax=axes[0])\n",
    "axes[0].set_xlabel(\"Frequency\")\n",
    "axes[0].set_ylabel(\"Words\")\n",
    "axes[0].set_title(\"Top 30 Word Frequencies in Train Dataset\")\n",
    "\n",
    "# test_df\n",
    "test_all_words = []\n",
    "for text in test_df['text']:\n",
    "    test_all_words.extend(word_tokenize(text.lower()))\n",
    "\n",
    "test_word_freq = Counter(test_all_words)\n",
    "\n",
    "test_most_common = test_word_freq.most_common(30)\n",
    "words, counts = zip(*test_most_common)\n",
    "\n",
    "sns.barplot(x=list(counts), y=list(words), ax=axes[1])\n",
    "axes[1].set_xlabel(\"Frequency\")\n",
    "axes[1].set_ylabel(\"Words\")\n",
    "axes[1].set_title(\"Top 30 Word Frequencies in Test Dataset\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidfvectorizer = TfidfVectorizer()\n",
    "X = tfidfvectorizer.fit_transform(train_df['text'])\n",
    "tfidf_features_name = tfidfvectorizer.get_feature_names_out()\n",
    "tfidf_features_name[100:110]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer here\n",
    "The numbers on the diagnal are right-predicted, and the others are wrong. The most wrong cases are 'fear' wrong-predicted as 'anger' then 'anger'\n",
    "wrong-predicted as 'fear'. We can hypothesis that it might be hard and stuggle for model to distinguish between 'fear' and 'anger'. For having more \n",
    "digged in details we can do error analysis to see what exact case will be predicted wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# model\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "# evaluate\n",
    "accuracy = accuracy_score(y_test_pred, y_test)\n",
    "print(f\"testing accuracy: {accuracy:.4f} \")\n",
    "\n",
    "# plot confusion matrix\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=y_test_pred)\n",
    "plot_confusion_matrix(cm, classes=my_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer here\n",
    "Naive Bayesåœ¨æ¸¬è©¦é›†ä¸Šçš„è¡¨ç¾è¼ƒDecision Treeä½³ï¼Œå¯èƒ½åŸå› æœ‰\n",
    "1. å„ç‰¹å¾µé–“ç‚ºç¨ç«‹å­˜åœ¨çš„ï¼Œä½¿å¾—Naive Bayesåœ¨æ­¤ç‹€æ³ä¸‹æ›´åŠ é©ç”¨(åŸºæ–¼æ¢ä»¶æ©Ÿç‡è¨ˆç®—çš„æ–¹å¼)\n",
    "2. Decision Treeå‡ºç¾éåº¦è¨˜æ†¶è¨“ç·´é›†çš„ç‰¹å¾µå°è‡´overfittingï¼Œåœ¨æ¸¬è©¦é›†ä¸Šè¡¨ç¾ä¸¦ä¸å¦‚é æœŸ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.plot(training_log['epoch'], training_log['accuracy'], color='blue')\n",
    "plt.plot(training_log['epoch'], training_log['val_accuracy'], color='red')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(['Train accuracy', 'Val accuracy'], loc='upper right')\n",
    "plt.title(\"Accuracy per epoch\");\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.plot(training_log['epoch'], training_log['loss'], color='blue')\n",
    "plt.plot(training_log['epoch'], training_log['val_loss'], color='red')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['Train loss', 'Val loss'], loc='upper right')\n",
    "plt.title(\"Loss per epoch\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the \"Training Loss per Epoch\" plot, the validation loss reaches its minimum at epoch 3. Beyond this point, as the number of epochs increases, the validation loss starts to rise while the training loss continues to decrease. This indicates that the model is overfitting after epoch 3, as it is learning the training set's patterns too well, leading to reduced generalization on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer here\n",
    "å¯èƒ½å¯ä»¥ä½¿ç”¨\n",
    "1. å°‡å¥å­ä¸­å‡ºç¾çš„vectoråŠ ç¸½æˆ–æ˜¯å–å¹³å‡ï¼Œå…¶å„ªé»æ˜¯ç°¡å–®å®¹æ˜“è¨ˆç®—ï¼Œç¼ºé»æ˜¯åŠ ç¸½æˆ–æ˜¯å¹³å‡çš„å‹•ä½œæœƒå°è‡´vectorä¹‹é–“å­˜åœ¨çš„é—œè¯è¢«æ¶ˆé™¤æ‰\n",
    "2. ä¹Ÿå¯åˆ©ç”¨åŠ æ¬Šçš„æ–¹å¼æ›¿è¼ƒé‡è¦çš„vectoræé«˜é‡è¦æ€§(é¡ä¼¼æ–¼TF-IDF)ï¼Œå„ªé»æ˜¯é‡è¦çš„vectoræœƒä½”è¼ƒå¤§çš„æ¯”ä¾‹ï¼Œç¼ºé»å‰‡æ˜¯éœ€è¦é¡å¤–è¨ˆç®—åŠ æ¬Šå€¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "similar_angry = [word[0] for word in w2v_google_model.most_similar('angry', topn=15)]\n",
    "similar_happy = [word[0] for word in  w2v_google_model.most_similar('happy', topn=15)]\n",
    "similar_sad = [word[0] for word in w2v_google_model.most_similar('sad', topn=15)]\n",
    "similar_fear = [word[0] for word in w2v_google_model.most_similar('fear', topn=15)]\n",
    "all_words = similar_angry + similar_happy +similar_sad + similar_fear\n",
    "\n",
    "model = w2v_google_model\n",
    "all_words_train = model[all_words]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6), dpi=115)\n",
    "\n",
    "# tsne\n",
    "tsne = TSNE(n_components=2, metric='cosine', random_state=33)\n",
    "all_words_tsne = tsne.fit_transform(all_words_train)\n",
    "\n",
    "color = ['b'] * 15 + ['r'] * 15 + ['y'] * 15 + ['g'] * 15\n",
    "\n",
    "axes[0].scatter(all_words_tsne[:, 0], all_words_tsne[:, 1], c=color)\n",
    "for label, x, y in zip(all_words, all_words_tsne[:, 0], all_words_tsne[:, 1]):\n",
    "    axes[0].annotate(label, xy=(x,y), xytext=(0,0),  textcoords='offset points')\n",
    "axes[0].set_title(\"TSNE Visualization\")\n",
    "\n",
    "# UMAP\n",
    "umap_model = umap.UMAP(n_components=2, metric='cosine', random_state=33)\n",
    "all_words_umap = umap_model.fit_transform(all_words_train)\n",
    "\n",
    "axes[1].scatter(all_words_umap[:, 0], all_words_umap[:, 1], c=color)\n",
    "for label, x, y in zip(all_words, all_words_umap[:, 0], all_words_umap[:, 1]):\n",
    "    axes[1].annotate(label, xy=(x,y), xytext=(0,0),  textcoords='offset points')\n",
    "axes[1].set_title(\"UMAP Visualization\")\n",
    "\n",
    "plt.tight_layout();\n",
    "\n",
    "# å¾å…©å¼µåœ–ä¸Šå¯ä»¥çœ‹åˆ° UMAPå„é¡çš„é»è¼ƒç‚ºå¯†é›†ï¼Œæœ€æ˜é¡¯çš„å·®è·åœ¨fearä¸­å¯ä»¥çœ‹åˆ°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "# roleçš„ç›®çš„æ˜¯å®šç¾©å°è©±çš„çµæ§‹ï¼Œä¾†çŸ¥é“ç¾åœ¨æ‡‰è©²æ˜¯èª°åœ¨èªªè©±ï¼Œroleåˆ†æˆ'user', 'system', 'assistant'ï¼ŒåŠ å…¥roleå¯å¼·åŒ–å°è©±é‚è¼¯\n",
    "response = ollama.chat(model='llama3.2', messages=[\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant knowledgeable about programming.\"\n",
    "    },\n",
    "])\n",
    "\n",
    "response = ollama.chat(model='llama3.2', messages=[\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Here's an example of a Python function:\\n```python\\ndef greet(name):\\n    return f'Hello, {name}!'\\n```\"\n",
    "    },\n",
    "])\n",
    "\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "# response3 = ollama.chat(model='llava-phi3', messages=[\n",
    "#     {\n",
    "#         'role': 'user',\n",
    "#         'content': 'What is this image about?',\n",
    "#         'images': ['./pics/pandas.jpg'] #Image with pandas\n",
    "#     },\n",
    "# ])\n",
    "\n",
    "# display(Markdown(response3['message']['content']))\n",
    "# # ä»–å½¢å®¹å¾—éå¸¸æº–ç¢ºï¼ŒåŒ…æ‹¬ç†Šè²“çš„æ•¸é‡ã€é€ æ™¯çš„è¨­è¨ˆåŠåœ–ç‰‡ä¸­è¼ƒæ¬¡è¦çš„å…‰å½±é‡é»ä¹Ÿè¡¨é”çš„éå¸¸è©³ç´°\n",
    "\n",
    "response3 = ollama.chat(model='llava-phi3', messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'What is this image about?',\n",
    "        'images': ['./pics/HappyNewYear.jpg'] #Image with crowds and fireworks\n",
    "    },\n",
    "])\n",
    "\n",
    "display(Markdown(response3['message']['content']))\n",
    "# æœ¬ä¾†ä»¥ç‚ºæ¨¡å‹æœƒå°è¼ƒç‚ºå¯†é›†ä¸”è³‡è¨Šé‡å¤§çš„åœ–ç‰‡å­˜åœ¨è§£è®€å›°é›£ï¼Œä½†å¾é€™å¼µåœ–ç‰‡çš„çµæœä¾†çœ‹è§£è®€çš„ç‹€æ³ä¸¦ä¸å·®ï¼Œä»–çœ‹åˆ°äº†ç…™ç«ã€äººç¾¤ã€ä¹ŸçŸ¥é“äººç¾¤æ˜¯åœ¨æ…¶ç¥è·¨å¹´(éå¸¸å¥½å¥‡æ˜¯æ€éº¼çŸ¥é“çš„)ã€ç”šè‡³ç¯€æ…¶æ°›åœéƒ½å½¢å®¹å¾—å¾ˆæº–ç¢º"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Answer here\n",
    "import ollama\n",
    "import bs4\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "llm_model = \"llama3.2\" #You can change to the one of your preference\n",
    "\n",
    "# Function to load, split, and retrieve documents\n",
    "def load_and_retrieve_docs(sources):\n",
    "    docs = []\n",
    "    for source in sources:\n",
    "        loader = WebBaseLoader(web_paths=(source,), bs_kwargs=dict()) \n",
    "        docs.extend(loader.load()) #We will load the URL that will serve as our data source\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200) #We will divide the URL in chunks of text for easier comparison in the vector space\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    # print(f\"splits: {splits} \") #You can print this to see how the chunks in the url where split\n",
    "    embeddings = OllamaEmbeddings(model=llm_model) #Generating embeddings with our chosen model\n",
    "    vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings) #Our vector space for comparison\n",
    "    return vectorstore.as_retriever()\n",
    "\n",
    "url=[\"https://www.ibm.com/topics/large-language-models\", \"https://en.wikipedia.org/wiki/Large_language_model\", \"https://www.ibm.com/topics/natural-language-processing\"]\n",
    "# Create the retriever\n",
    "retriever = load_and_retrieve_docs(url)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs) #Format the retrieved docs in an orderly manner for prompting\n",
    "\n",
    "# Define the Ollama LLM function\n",
    "def ollama_llm(question, context):\n",
    "    formatted_prompt = f\"Question: {question}\\n\\nContext: {context}\"\n",
    "    response = ollama.chat(model='llama3.2', messages=[{'role': 'user', 'content': formatted_prompt}])\n",
    "    return response['message']['content']\n",
    "\n",
    "# Define the RAG chain\n",
    "def rag_chain(question):\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    formatted_context = format_docs(retrieved_docs)\n",
    "    return ollama_llm(question, formatted_context)\n",
    "\n",
    "# Use the RAG chain\n",
    "result = rag_chain(\"What are the related solutions of IBM with LLMs?\")\n",
    "display(Markdown(result))\n",
    "\n",
    "# ç•¶æ–°åŠ å…¥æ›´å¤šçš„æ–‡ç« åƒè€ƒåè€Œé€ æˆå›æ‡‰çš„æº–ç¢ºåº¦é™ä½ï¼ŒRAGçš„ç¼ºé»å¯èƒ½åŒ…æ‹¬ç•¶æª¢ç´¢åˆ°çš„æ–‡æª”èˆ‡å•é¡Œçš„ç›¸é—œæ€§éä½æ™‚ï¼Œæœƒå°è‡´ç”Ÿæˆå›æ‡‰çš„æº–ç¢ºåº¦é™ä½ä¸”éå¤šä½è³ªæˆ–ç„¡é—œçš„æ–‡æª”å¯èƒ½å¹²æ“¾æ¨¡å‹ï¼Œå¢åŠ éŒ¯èª¤è³‡è¨Šçš„ç”¢ç”Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Answer here\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
    "\n",
    "axes[0].plot(training_log['epoch'], training_log['accuracy'], color='blue')\n",
    "axes[0].plot(training_log['epoch'], training_log['val_accuracy'], color='red')\n",
    "axes[0].set_xlabel(\"Epochs\")\n",
    "axes[0].set_ylabel(\"Accuracy\")\n",
    "axes[0].legend(['Train accuracy', 'Val accuracy'], loc='upper right')\n",
    "axes[0].set_title(\"Accuracy per epoch\");\n",
    "\n",
    "axes[1].plot(training_log['epoch'], training_log['loss'], color='blue')\n",
    "axes[1].plot(training_log['epoch'], training_log['val_loss'], color='red')\n",
    "axes[1].set_xlabel(\"Epochs\")\n",
    "axes[1].set_ylabel(\"Loss\")\n",
    "axes[1].legend(['Train loss', 'Val loss'], loc='upper right')\n",
    "axes[1].set_title(\"Loss per epoch\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ ¹æ“šåœ–è¡¨æˆ‘å€‘å¯ä»¥çœ‹åˆ°NNåœ¨è¨“ç·´é›†ä¸Šçš„è¡¨ç¾éƒ½éå¸¸å¥½ï¼Œä½†åœ¨æ¸¬è©¦é›†ä¸Šçš„è¡¨ç¾å»ä¸å¦‚è¨“ç·´é›†ï¼Œé€™æ˜¯å¾ˆå…¸å‹çš„overfittingçš„ç‹€æ³ï¼Œå¯èƒ½åŸå› æ˜¯è³‡æ–™é›†å¤§å°å¤ªå°ï¼Œå°è‡´æ¨¡å‹å·²ç¶“éåˆ†è¨˜æ†¶è¨“ç·´é›†ä¸­çš„å„å€‹ç‰¹å¾µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer here\n",
    "è‹¥åˆ†ç‚ºä¸æä¾›ä¾‹å­(zero-shot))åŠæœ‰æä¾›ä¾‹å­(1-shot and 5-shot)ï¼Œå‰‡ç‚ºæä¾›ä¾‹å­çš„è¡¨ç¾è¼ƒæä¾›çš„ç•¥é«˜ä¸€é»;\n",
    "æ¨æ¸¬å¯èƒ½ç‚ºæ¨¡å‹å°ä»»å‹™å·²ç¶“ååˆ†ç†Ÿæ‚‰ï¼Œ1-shotå·²è¶³å¤ è®“å…¶äº†è§£ï¼Œæ•…é¡å¤–çš„ä¾‹å­å°å…¶çš„æ•ˆæœä¾¿æ²’é‚£éº¼å¥½äº†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### =======================Second Part================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import emoji\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import transformers\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tweet = \"tweets_DM.json\"\n",
    "data = []\n",
    "with open(raw_tweet, \"r\") as f_in:\n",
    "    for line in f_in:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "data_identification = pd.read_csv(\"./data_identification.csv\")\n",
    "submission = pd.read_csv(\"./sampleSubmission.csv\")\n",
    "# submission.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°‡emojiè½‰æ›æˆç‰¹å®štoken\n",
    "# emoji_dict = {\n",
    "#     'ğŸ˜‚': '[emoji]',\n",
    "#     'â¤ï¸': '[emoji]',\n",
    "#     'ğŸ˜': '[emoji]',\n",
    "#     'ğŸ˜­': '[emoji]',\n",
    "#     'â¤': '[emoji]',\n",
    "#     'ğŸ˜Š': '[emoji]',\n",
    "#     'ğŸ™': '[emoji]',\n",
    "#     'ğŸ˜˜': '[emoji]',\n",
    "#     'ğŸ’•': '[emoji]',\n",
    "#     'ğŸ”¥': '[emoji]',\n",
    "#     'ğŸ˜©': '[emoji]',\n",
    "#     'ğŸ¤”': '[emoji]',\n",
    "#     'ğŸ’¯': '[emoji]',\n",
    "#     'ğŸ’™': '[emoji]',\n",
    "#     'ğŸ™„': '[emoji]',\n",
    "#     'ğŸ˜': '[emoji]',\n",
    "#     'ğŸ™Œ': '[emoji]',\n",
    "#     'ğŸ™ğŸ¾': '[emoji]',\n",
    "#     'ğŸ‘': '[emoji]',\n",
    "#     'ğŸ™ğŸ½': '[emoji]'\n",
    "# }\n",
    "\n",
    "emoji_dict = {\n",
    "    'ğŸ˜‚': '[joy]',\n",
    "    'â¤ï¸': '[love]',\n",
    "    'ğŸ˜': '[adoration]',\n",
    "    'ğŸ˜­': '[cry]',\n",
    "    'â¤': '[care]',\n",
    "    'ğŸ˜Š': '[happy]',\n",
    "    'ğŸ™': '[pray]',\n",
    "    'ğŸ˜˜': '[kiss]',\n",
    "    'ğŸ’•': '[love_each_other]',\n",
    "    'ğŸ”¥': '[fire]',\n",
    "    'ğŸ˜©': '[weary]',\n",
    "    'ğŸ¤”': '[think]',\n",
    "    'ğŸ’¯': '[perfect]',\n",
    "    'ğŸ’™': '[loyalty]',\n",
    "    'ğŸ™„': '[annoyed]',\n",
    "    'ğŸ˜': '[happy]',\n",
    "    'ğŸ™Œ': '[celebrate]',\n",
    "    'ğŸ™ğŸ¾': '[pray]',\n",
    "    'ğŸ‘': '[approve]',\n",
    "    'ğŸ™ğŸ½': '[pray]'\n",
    "}\n",
    "\n",
    "def clean_tweet(text, emoji_dict):\n",
    "    # å°‡å®šç¾©çš„è¡¨æƒ…ç¬¦è™Ÿæ›¿æ›ç‚ºå°æ‡‰çš„é—œéµè©\n",
    "    for emj, keyword in emoji_dict.items():\n",
    "        text = text.replace(emj, keyword)\n",
    "    text = emoji.replace_emoji(text, replace='')\n",
    "    text = re.sub(r'<LH>', '', text)\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_tweets = []\n",
    "# for entry in data:\n",
    "#     if '_source' in entry and 'tweet' in entry['_source']:\n",
    "#         tweet = entry['_source']['tweet']\n",
    "#         if 'text' in tweet:\n",
    "#             tweet_text = tweet['text']\n",
    "#             cleaned_text = clean_tweet(tweet_text, emoji_dict)\n",
    "#             processed_tweet = {\n",
    "#                 '_source': {\n",
    "#                     'tweet': tweet.copy()\n",
    "#                 }\n",
    "#             }\n",
    "#             processed_tweet['_source']['tweet']['text'] = cleaned_text\n",
    "#             processed_tweets.append(processed_tweet)\n",
    "#         else:\n",
    "#             print(\"è¨˜éŒ„ä¸­ç¼ºå°‘ 'text' éµ\")\n",
    "#     else:\n",
    "#         print(\"è¨˜éŒ„ä¸­ç¼ºå°‘ '_source' æˆ– 'tweet' éµ\")\n",
    "\n",
    "# with open('tweets_DM_filtered_1.json', 'w', encoding='utf-8') as outfile:\n",
    "#     json.dump(processed_tweets, outfile, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tweets = []\n",
    "with open('tweets_DM_filtered_emoji.json', 'r', encoding='utf-8') as f_in:\n",
    "  data = json.load(f_in)\n",
    "  processed_tweets.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°‡è™•ç†å¾Œçš„è³‡æ–™è½‰æ›ç‚º DataFrame\n",
    "df_processed = pd.DataFrame(processed_tweets)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "_source = df['_source'].apply(lambda x: x['tweet'])\n",
    "df = pd.DataFrame({\n",
    "    'tweet_id': _source.apply(lambda x: x['tweet_id']),\n",
    "    'hashtags': _source.apply(lambda x: x['hashtags']),\n",
    "    'text': _source.apply(lambda x: x['text']),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(data_identification, on='tweet_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "joy             516017\n",
       "anticipation    248935\n",
       "trust           205478\n",
       "sadness         193437\n",
       "disgust         139101\n",
       "fear             63999\n",
       "surprise         48729\n",
       "anger            39867\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions = pd.read_csv(\"emotion.csv\")\n",
    "emotions['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1816555/2092790352.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data.rename(columns={'tweet_id': 'id', 'hashtags': 'hashtags', 'text':'text', 'identification': 'identification'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# åˆ©ç”¨data_identification.csvä¸­çš„è³‡æ–™æ‹†åˆ†å‡ºtraining setåŠtesting set\n",
    "train_data = df[df['identification'] == 'train']\n",
    "test_data = df[df['identification'] == 'test']\n",
    "train_data = train_data.merge(emotions, on='tweet_id', how='left')\n",
    "train_data.drop_duplicates(subset=['text'], keep=False, inplace=True)\n",
    "\n",
    "# çµ±ä¸€submissionè·Ÿtest_dataçš„é †åºï¼Œä»¥æ–¹ä¾¿å¾ŒçºŒé æ¸¬çµæŸå¾Œå¡«å…¥\n",
    "test_data.rename(columns={'tweet_id': 'id', 'hashtags': 'hashtags', 'text':'text', 'identification': 'identification'}, inplace=True)\n",
    "\n",
    "new_submission = submission.copy()\n",
    "\n",
    "new_submission = new_submission.merge(test_data, on='id')\n",
    "new_submission.drop(['hashtags', 'identification'], axis='columns', inplace=True)\n",
    "\n",
    "y_train_data = train_data['emotion']\n",
    "X_train_data = train_data['text']\n",
    "X_test_data = new_submission['text']\n",
    "\n",
    "# åˆ©ç”¨oneHot encodingå°‡æ¨™ç±¤è½‰æˆç·¨ç¢¼\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_train = le.fit_transform(y_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_submission.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_data, y_train, test_size=0.3, random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æƒ³åˆ©ç”¨ä¸åŒçš„æ¨¡å‹ä¾†é”åˆ°è¨ˆç®—è³‡æºåŠæº–ç¢ºåº¦çš„å¹³è¡¡ï¼Œä½¿ç”¨äº†TinyBert, distilber, BERT\n",
    "from transformers import BertTokenizer, BertModel, DistilBertTokenizer\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"huawei-noah/TinyBERT_General_4L_312D\")\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "max_length = 50\n",
    "tokenized_train = tokenizer(X_train.tolist(), max_length=max_length, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "# tokenized_val = tokenizer(X_val.tolist(), max_length=max_length, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "tokenized_test = tokenizer(X_test_data.tolist(), max_length=max_length, truncation=True, padding=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenized_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch import nn\n",
    "# from transformers import BertModel, BertTokenizer\n",
    "\n",
    "# class BertClassifier(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(BertClassifier, self).__init__()\n",
    "#         self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "#         # self.bert = BertModel.from_pretrained(\"huawei-noah/TinyBERT_General_4L_312D\")\n",
    "#         self.classifier = nn.Linear(self.bert.config.hidden_size, 8)\n",
    "\n",
    "#     def forward(self, input_ids, attention_mask, token_type_ids=None):\n",
    "#         # BERT æ¨¡å‹è¼¸å‡º\n",
    "#         outputs = self.bert(input_ids=input_ids, \n",
    "#                             attention_mask=attention_mask, \n",
    "#                             token_type_ids=token_type_ids\n",
    "#                             )\n",
    "#         pooled_output = outputs.pooler_output  # BERT çš„ [CLS] token è¡¨ç¤º\n",
    "#         logits = self.classifier(pooled_output)  # ç·šæ€§å±¤é€²è¡Œåˆ†é¡\n",
    "#         return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import DistilBertModel\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        # ä½¿ç”¨ DistilBERT æ¨¡å‹\n",
    "        self.bert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, 8)  # å‡è¨­æœ‰ 8 å€‹åˆ†é¡\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # DistilBERT è¼¸å‡º last_hidden_state\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        # ä½¿ç”¨ last_hidden_state çš„ç¬¬ä¸€å€‹ token ä½œç‚ºå¥å­çš„è¡¨ç¤º\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]  # å– [CLS] token åµŒå…¥\n",
    "        logits = self.classifier(cls_output)  # ç·šæ€§å±¤é€²è¡Œåˆ†é¡\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BertClassifier().to(device)\n",
    "\n",
    "input_ids = torch.tensor(tokenized_train['input_ids'].numpy()).to(device)\n",
    "attention_mask = torch.tensor(tokenized_train['attention_mask'].numpy()).to(device)\n",
    "# token_type_ids = torch.tensor(tokenized_train['token_type_ids'].numpy()).to(device)\n",
    "\n",
    "train_input = {\n",
    "    'input_ids': input_ids,\n",
    "    'attention_mask': attention_mask,\n",
    "    # 'token_type_ids': token_type_ids,\n",
    "}\n",
    "\n",
    "y_train = torch.tensor(y_train).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62979/62979 [36:18<00:00, 28.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Loss: 1.0975, Accuracy: 0.6032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62979/62979 [36:30<00:00, 28.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "Loss: 0.9498, Accuracy: 0.6572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62979/62979 [36:30<00:00, 28.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n",
      "Loss: 0.8409, Accuracy: 0.6970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62979/62979 [36:30<00:00, 28.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n",
      "Loss: 0.7326, Accuracy: 0.7361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62979/62979 [36:33<00:00, 28.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n",
      "Loss: 0.6289, Accuracy: 0.7739\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 16\n",
    "dataset = torch.utils.data.TensorDataset(\n",
    "    train_input['input_ids'], train_input['attention_mask'], y_train\n",
    ")\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for batch in tqdm(dataloader):\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model(input_ids, attention_mask)\n",
    "        \n",
    "        # è¨ˆç®—æå¤±\n",
    "        loss = criterion(logits, labels)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # è¨ˆç®—æº–ç¢ºç‡\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += (preds == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # æ¯å€‹ epoch çµæŸå¾Œï¼Œè¨ˆç®—å¹³å‡æå¤±å’Œæº–ç¢ºç‡\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    print(f\"Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    if epoch == 3:\n",
    "        torch.save(model.state_dict(), \"distilbert_classifier_model_epoch_3.pth\")\n",
    "\n",
    "# ä¿å­˜æ¨¡å‹\n",
    "torch.save(model.state_dict(), \"distilbert_classifier_model_epoch_5.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"distilbert_classifier_model_epoch_3.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(tokenized_test['input_ids'], tokenized_test['attention_mask'])\n",
    "batch_size = 16\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids = torch.tensor(tokenized_val['input_ids'].numpy()).to(device)\n",
    "# attention_mask = torch.tensor(tokenized_val['attention_mask'].numpy()).to(device)\n",
    "# token_type_ids = torch.tensor(tokenized_val['token_type_ids'].numpy()).to(device)\n",
    "test_ids = torch.tensor(tokenized_test['input_ids'].numpy()).to(device)\n",
    "test_attention_mask = torch.tensor(tokenized_test['attention_mask'].numpy()).to(device)\n",
    "\n",
    "# val_input = {\n",
    "#     'input_ids': input_ids,\n",
    "#     'attention_mask': attention_mask,\n",
    "#     # 'token_type_ids': token_type_ids,\n",
    "# }\n",
    "\n",
    "test_input = {\n",
    "    'input_ids': test_ids,\n",
    "    'attention_mask': test_attention_mask\n",
    "}\n",
    "\n",
    "# y_val = torch.tensor(y_val).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "model.eval()  # è¨­ç½®æ¨¡å‹ç‚ºè©•ä¼°æ¨¡å¼\n",
    "with torch.no_grad():  # æ¨ç†æ™‚ä¸è¨ˆç®—æ¢¯åº¦\n",
    "    for batch in tqdm(test_loader):\n",
    "        input_ids, attention_mask = [x.to(device) for x in batch]\n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        probabilities = torch.softmax(logits, dim=-1)\n",
    "        predictions = torch.argmax(probabilities, dim=-1)\n",
    "        class_labels = le.inverse_transform(predictions.cpu())\n",
    "        pred.extend(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['emotion'] = pred\n",
    "submission.to_csv(\"submission_distilbert_epoch_5.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
