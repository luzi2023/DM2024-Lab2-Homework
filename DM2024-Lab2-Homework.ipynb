{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name: 盧子涵\n",
    "\n",
    "Student ID: 113065542\n",
    "\n",
    "GitHub ID: luzi2023\n",
    "\n",
    "Kaggle name: luzi8451\n",
    "\n",
    "Kaggle private scoreboard snapshot: ![pic0.png](attachment:\"img/pic0.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "image/png": {
       "height": 600,
       "width": 850
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "PATH = \"img/pic0.png\"\n",
    "Image(filename = PATH , width=850, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home exercises** in the [DM2024-Lab2-master Repo](https://github.com/didiersalazar/DM2024-Lab2-Master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework) regarding Emotion Recognition on Twitter by this link: https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
    "    Submit your last submission **BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)**. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developing the model for the competition (You can use code and comment on it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### =======================First Part================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# train_df\n",
    "train_all_words = []\n",
    "for text in train_df['text']:\n",
    "    train_all_words.extend(word_tokenize(text.lower()))\n",
    "    \n",
    "train_word_freq = Counter(train_all_words)\n",
    "    \n",
    "train_most_common = train_word_freq.most_common(30)\n",
    "words, counts = zip(*train_most_common)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "sns.barplot(x=list(counts), y=list(words), ax=axes[0])\n",
    "axes[0].set_xlabel(\"Frequency\")\n",
    "axes[0].set_ylabel(\"Words\")\n",
    "axes[0].set_title(\"Top 30 Word Frequencies in Train Dataset\")\n",
    "\n",
    "# test_df\n",
    "test_all_words = []\n",
    "for text in test_df['text']:\n",
    "    test_all_words.extend(word_tokenize(text.lower()))\n",
    "\n",
    "test_word_freq = Counter(test_all_words)\n",
    "\n",
    "test_most_common = test_word_freq.most_common(30)\n",
    "words, counts = zip(*test_most_common)\n",
    "\n",
    "sns.barplot(x=list(counts), y=list(words), ax=axes[1])\n",
    "axes[1].set_xlabel(\"Frequency\")\n",
    "axes[1].set_ylabel(\"Words\")\n",
    "axes[1].set_title(\"Top 30 Word Frequencies in Test Dataset\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidfvectorizer = TfidfVectorizer()\n",
    "X = tfidfvectorizer.fit_transform(train_df['text'])\n",
    "tfidf_features_name = tfidfvectorizer.get_feature_names_out()\n",
    "tfidf_features_name[100:110]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer here\n",
    "The numbers on the diagnal are right-predicted, and the others are wrong. The most wrong cases are 'fear' wrong-predicted as 'anger' then 'anger'\n",
    "wrong-predicted as 'fear'. We can hypothesis that it might be hard and stuggle for model to distinguish between 'fear' and 'anger'. For having more \n",
    "digged in details we can do error analysis to see what exact case will be predicted wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# model\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "# evaluate\n",
    "accuracy = accuracy_score(y_test_pred, y_test)\n",
    "print(f\"testing accuracy: {accuracy:.4f} \")\n",
    "\n",
    "# plot confusion matrix\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=y_test_pred)\n",
    "plot_confusion_matrix(cm, classes=my_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Answer here\n",
    "Naive Bayes在測試集上的表現較Decision Tree佳，可能原因有\n",
    "1. 各特徵間為獨立存在的，使得Naive Bayes在此狀況下更加適用(基於條件機率計算的方式)\n",
    "2. Decision Tree出現過度記憶訓練集的特徵導致overfitting，在測試集上表現並不如預期"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.plot(training_log['epoch'], training_log['accuracy'], color='blue')\n",
    "plt.plot(training_log['epoch'], training_log['val_accuracy'], color='red')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(['Train accuracy', 'Val accuracy'], loc='upper right')\n",
    "plt.title(\"Accuracy per epoch\");\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.plot(training_log['epoch'], training_log['loss'], color='blue')\n",
    "plt.plot(training_log['epoch'], training_log['val_loss'], color='red')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['Train loss', 'Val loss'], loc='upper right')\n",
    "plt.title(\"Loss per epoch\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the \"Training Loss per Epoch\" plot, the validation loss reaches its minimum at epoch 3. Beyond this point, as the number of epochs increases, the validation loss starts to rise while the training loss continues to decrease. This indicates that the model is overfitting after epoch 3, as it is learning the training set's patterns too well, leading to reduced generalization on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer here\n",
    "可能可以使用\n",
    "1. 將句子中出現的vector加總或是取平均，其優點是簡單容易計算，缺點是加總或是平均的動作會導致vector之間存在的關聯被消除掉\n",
    "2. 也可利用加權的方式替較重要的vector提高重要性(類似於TF-IDF)，優點是重要的vector會佔較大的比例，缺點則是需要額外計算加權值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "similar_angry = [word[0] for word in w2v_google_model.most_similar('angry', topn=15)]\n",
    "similar_happy = [word[0] for word in  w2v_google_model.most_similar('happy', topn=15)]\n",
    "similar_sad = [word[0] for word in w2v_google_model.most_similar('sad', topn=15)]\n",
    "similar_fear = [word[0] for word in w2v_google_model.most_similar('fear', topn=15)]\n",
    "all_words = similar_angry + similar_happy +similar_sad + similar_fear\n",
    "\n",
    "model = w2v_google_model\n",
    "all_words_train = model[all_words]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6), dpi=115)\n",
    "\n",
    "# tsne\n",
    "tsne = TSNE(n_components=2, metric='cosine', random_state=33)\n",
    "all_words_tsne = tsne.fit_transform(all_words_train)\n",
    "\n",
    "color = ['b'] * 15 + ['r'] * 15 + ['y'] * 15 + ['g'] * 15\n",
    "\n",
    "axes[0].scatter(all_words_tsne[:, 0], all_words_tsne[:, 1], c=color)\n",
    "for label, x, y in zip(all_words, all_words_tsne[:, 0], all_words_tsne[:, 1]):\n",
    "    axes[0].annotate(label, xy=(x,y), xytext=(0,0),  textcoords='offset points')\n",
    "axes[0].set_title(\"TSNE Visualization\")\n",
    "\n",
    "# UMAP\n",
    "umap_model = umap.UMAP(n_components=2, metric='cosine', random_state=33)\n",
    "all_words_umap = umap_model.fit_transform(all_words_train)\n",
    "\n",
    "axes[1].scatter(all_words_umap[:, 0], all_words_umap[:, 1], c=color)\n",
    "for label, x, y in zip(all_words, all_words_umap[:, 0], all_words_umap[:, 1]):\n",
    "    axes[1].annotate(label, xy=(x,y), xytext=(0,0),  textcoords='offset points')\n",
    "axes[1].set_title(\"UMAP Visualization\")\n",
    "\n",
    "plt.tight_layout();\n",
    "\n",
    "# 從兩張圖上可以看到 UMAP各類的點較為密集，最明顯的差距在fear中可以看到"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "# role的目的是定義對話的結構，來知道現在應該是誰在說話，role分成'user', 'system', 'assistant'，加入role可強化對話邏輯\n",
    "response = ollama.chat(model='llama3.2', messages=[\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant knowledgeable about programming.\"\n",
    "    },\n",
    "])\n",
    "\n",
    "response = ollama.chat(model='llama3.2', messages=[\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Here's an example of a Python function:\\n```python\\ndef greet(name):\\n    return f'Hello, {name}!'\\n```\"\n",
    "    },\n",
    "])\n",
    "\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "# response3 = ollama.chat(model='llava-phi3', messages=[\n",
    "#     {\n",
    "#         'role': 'user',\n",
    "#         'content': 'What is this image about?',\n",
    "#         'images': ['./pics/pandas.jpg'] #Image with pandas\n",
    "#     },\n",
    "# ])\n",
    "\n",
    "# display(Markdown(response3['message']['content']))\n",
    "# # 他形容得非常準確，包括熊貓的數量、造景的設計及圖片中較次要的光影重點也表達的非常詳細\n",
    "\n",
    "response3 = ollama.chat(model='llava-phi3', messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': 'What is this image about?',\n",
    "        'images': ['./pics/HappyNewYear.jpg'] #Image with crowds and fireworks\n",
    "    },\n",
    "])\n",
    "\n",
    "display(Markdown(response3['message']['content']))\n",
    "# 本來以為模型會對較為密集且資訊量大的圖片存在解讀困難，但從這張圖片的結果來看解讀的狀況並不差，他看到了煙火、人群、也知道人群是在慶祝跨年(非常好奇是怎麼知道的)、甚至節慶氛圍都形容得很準確"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Answer here\n",
    "import ollama\n",
    "import bs4\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "llm_model = \"llama3.2\" #You can change to the one of your preference\n",
    "\n",
    "# Function to load, split, and retrieve documents\n",
    "def load_and_retrieve_docs(sources):\n",
    "    docs = []\n",
    "    for source in sources:\n",
    "        loader = WebBaseLoader(web_paths=(source,), bs_kwargs=dict()) \n",
    "        docs.extend(loader.load()) #We will load the URL that will serve as our data source\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200) #We will divide the URL in chunks of text for easier comparison in the vector space\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    # print(f\"splits: {splits} \") #You can print this to see how the chunks in the url where split\n",
    "    embeddings = OllamaEmbeddings(model=llm_model) #Generating embeddings with our chosen model\n",
    "    vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings) #Our vector space for comparison\n",
    "    return vectorstore.as_retriever()\n",
    "\n",
    "url=[\"https://www.ibm.com/topics/large-language-models\", \"https://en.wikipedia.org/wiki/Large_language_model\", \"https://www.ibm.com/topics/natural-language-processing\"]\n",
    "# Create the retriever\n",
    "retriever = load_and_retrieve_docs(url)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs) #Format the retrieved docs in an orderly manner for prompting\n",
    "\n",
    "# Define the Ollama LLM function\n",
    "def ollama_llm(question, context):\n",
    "    formatted_prompt = f\"Question: {question}\\n\\nContext: {context}\"\n",
    "    response = ollama.chat(model='llama3.2', messages=[{'role': 'user', 'content': formatted_prompt}])\n",
    "    return response['message']['content']\n",
    "\n",
    "# Define the RAG chain\n",
    "def rag_chain(question):\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    formatted_context = format_docs(retrieved_docs)\n",
    "    return ollama_llm(question, formatted_context)\n",
    "\n",
    "# Use the RAG chain\n",
    "result = rag_chain(\"What are the related solutions of IBM with LLMs?\")\n",
    "display(Markdown(result))\n",
    "\n",
    "# 當新加入更多的文章參考反而造成回應的準確度降低，RAG的缺點可能包括當檢索到的文檔與問題的相關性過低時，會導致生成回應的準確度降低且過多低質或無關的文檔可能干擾模型，增加錯誤資訊的產生"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Answer here\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
    "\n",
    "axes[0].plot(training_log['epoch'], training_log['accuracy'], color='blue')\n",
    "axes[0].plot(training_log['epoch'], training_log['val_accuracy'], color='red')\n",
    "axes[0].set_xlabel(\"Epochs\")\n",
    "axes[0].set_ylabel(\"Accuracy\")\n",
    "axes[0].legend(['Train accuracy', 'Val accuracy'], loc='upper right')\n",
    "axes[0].set_title(\"Accuracy per epoch\");\n",
    "\n",
    "axes[1].plot(training_log['epoch'], training_log['loss'], color='blue')\n",
    "axes[1].plot(training_log['epoch'], training_log['val_loss'], color='red')\n",
    "axes[1].set_xlabel(\"Epochs\")\n",
    "axes[1].set_ylabel(\"Loss\")\n",
    "axes[1].legend(['Train loss', 'Val loss'], loc='upper right')\n",
    "axes[1].set_title(\"Loss per epoch\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根據圖表我們可以看到NN在訓練集上的表現都非常好，但在測試集上的表現卻不如訓練集，這是很典型的overfitting的狀況，可能原因是資料集大小太小，導致模型已經過分記憶訓練集中的各個特徵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer here\n",
    "若分為不提供例子(zero-shot))及有提供例子(1-shot and 5-shot)，則為提供例子的表現較提供的略高一點;\n",
    "推測可能為模型對任務已經十分熟悉，1-shot已足夠讓其了解，故額外的例子對其的效果便沒那麼好了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### =======================Second Part================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import emoji\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import transformers\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tweet = \"tweets_DM.json\"\n",
    "data = []\n",
    "with open(raw_tweet, \"r\") as f_in:\n",
    "    for line in f_in:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "data_identification = pd.read_csv(\"./data_identification.csv\")\n",
    "submission = pd.read_csv(\"./sampleSubmission.csv\")\n",
    "# submission.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將emoji轉換成特定token\n",
    "# emoji_dict = {\n",
    "#     '😂': '[emoji]',\n",
    "#     '❤️': '[emoji]',\n",
    "#     '😍': '[emoji]',\n",
    "#     '😭': '[emoji]',\n",
    "#     '❤': '[emoji]',\n",
    "#     '😊': '[emoji]',\n",
    "#     '🙏': '[emoji]',\n",
    "#     '😘': '[emoji]',\n",
    "#     '💕': '[emoji]',\n",
    "#     '🔥': '[emoji]',\n",
    "#     '😩': '[emoji]',\n",
    "#     '🤔': '[emoji]',\n",
    "#     '💯': '[emoji]',\n",
    "#     '💙': '[emoji]',\n",
    "#     '🙄': '[emoji]',\n",
    "#     '😁': '[emoji]',\n",
    "#     '🙌': '[emoji]',\n",
    "#     '🙏🏾': '[emoji]',\n",
    "#     '👍': '[emoji]',\n",
    "#     '🙏🏽': '[emoji]'\n",
    "# }\n",
    "\n",
    "emoji_dict = {\n",
    "    '😂': '[joy]',\n",
    "    '❤️': '[love]',\n",
    "    '😍': '[adoration]',\n",
    "    '😭': '[cry]',\n",
    "    '❤': '[care]',\n",
    "    '😊': '[happy]',\n",
    "    '🙏': '[pray]',\n",
    "    '😘': '[kiss]',\n",
    "    '💕': '[love_each_other]',\n",
    "    '🔥': '[fire]',\n",
    "    '😩': '[weary]',\n",
    "    '🤔': '[think]',\n",
    "    '💯': '[perfect]',\n",
    "    '💙': '[loyalty]',\n",
    "    '🙄': '[annoyed]',\n",
    "    '😁': '[happy]',\n",
    "    '🙌': '[celebrate]',\n",
    "    '🙏🏾': '[pray]',\n",
    "    '👍': '[approve]',\n",
    "    '🙏🏽': '[pray]'\n",
    "}\n",
    "\n",
    "def clean_tweet(text, emoji_dict):\n",
    "    # 將定義的表情符號替換為對應的關鍵詞\n",
    "    for emj, keyword in emoji_dict.items():\n",
    "        text = text.replace(emj, keyword)\n",
    "    text = emoji.replace_emoji(text, replace='')\n",
    "    text = re.sub(r'<LH>', '', text)\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_tweets = []\n",
    "# for entry in data:\n",
    "#     if '_source' in entry and 'tweet' in entry['_source']:\n",
    "#         tweet = entry['_source']['tweet']\n",
    "#         if 'text' in tweet:\n",
    "#             tweet_text = tweet['text']\n",
    "#             cleaned_text = clean_tweet(tweet_text, emoji_dict)\n",
    "#             processed_tweet = {\n",
    "#                 '_source': {\n",
    "#                     'tweet': tweet.copy()\n",
    "#                 }\n",
    "#             }\n",
    "#             processed_tweet['_source']['tweet']['text'] = cleaned_text\n",
    "#             processed_tweets.append(processed_tweet)\n",
    "#         else:\n",
    "#             print(\"記錄中缺少 'text' 鍵\")\n",
    "#     else:\n",
    "#         print(\"記錄中缺少 '_source' 或 'tweet' 鍵\")\n",
    "\n",
    "# with open('tweets_DM_filtered_1.json', 'w', encoding='utf-8') as outfile:\n",
    "#     json.dump(processed_tweets, outfile, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tweets = []\n",
    "with open('tweets_DM_filtered_emoji.json', 'r', encoding='utf-8') as f_in:\n",
    "  data = json.load(f_in)\n",
    "  processed_tweets.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將處理後的資料轉換為 DataFrame\n",
    "df_processed = pd.DataFrame(processed_tweets)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "_source = df['_source'].apply(lambda x: x['tweet'])\n",
    "df = pd.DataFrame({\n",
    "    'tweet_id': _source.apply(lambda x: x['tweet_id']),\n",
    "    'hashtags': _source.apply(lambda x: x['hashtags']),\n",
    "    'text': _source.apply(lambda x: x['text']),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(data_identification, on='tweet_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "joy             516017\n",
       "anticipation    248935\n",
       "trust           205478\n",
       "sadness         193437\n",
       "disgust         139101\n",
       "fear             63999\n",
       "surprise         48729\n",
       "anger            39867\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions = pd.read_csv(\"emotion.csv\")\n",
    "emotions['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1816555/2092790352.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_data.rename(columns={'tweet_id': 'id', 'hashtags': 'hashtags', 'text':'text', 'identification': 'identification'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# 利用data_identification.csv中的資料拆分出training set及testing set\n",
    "train_data = df[df['identification'] == 'train']\n",
    "test_data = df[df['identification'] == 'test']\n",
    "train_data = train_data.merge(emotions, on='tweet_id', how='left')\n",
    "train_data.drop_duplicates(subset=['text'], keep=False, inplace=True)\n",
    "\n",
    "# 統一submission跟test_data的順序，以方便後續預測結束後填入\n",
    "test_data.rename(columns={'tweet_id': 'id', 'hashtags': 'hashtags', 'text':'text', 'identification': 'identification'}, inplace=True)\n",
    "\n",
    "new_submission = submission.copy()\n",
    "\n",
    "new_submission = new_submission.merge(test_data, on='id')\n",
    "new_submission.drop(['hashtags', 'identification'], axis='columns', inplace=True)\n",
    "\n",
    "y_train_data = train_data['emotion']\n",
    "X_train_data = train_data['text']\n",
    "X_test_data = new_submission['text']\n",
    "\n",
    "# 利用oneHot encoding將標籤轉成編碼\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_train = le.fit_transform(y_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_submission.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_data, y_train, test_size=0.3, random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 想利用不同的模型來達到計算資源及準確度的平衡，使用了TinyBert, distilber, BERT\n",
    "from transformers import BertTokenizer, BertModel, DistilBertTokenizer\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"huawei-noah/TinyBERT_General_4L_312D\")\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "max_length = 50\n",
    "tokenized_train = tokenizer(X_train.tolist(), max_length=max_length, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "# tokenized_val = tokenizer(X_val.tolist(), max_length=max_length, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "tokenized_test = tokenizer(X_test_data.tolist(), max_length=max_length, truncation=True, padding=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenized_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch import nn\n",
    "# from transformers import BertModel, BertTokenizer\n",
    "\n",
    "# class BertClassifier(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(BertClassifier, self).__init__()\n",
    "#         self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "#         # self.bert = BertModel.from_pretrained(\"huawei-noah/TinyBERT_General_4L_312D\")\n",
    "#         self.classifier = nn.Linear(self.bert.config.hidden_size, 8)\n",
    "\n",
    "#     def forward(self, input_ids, attention_mask, token_type_ids=None):\n",
    "#         # BERT 模型輸出\n",
    "#         outputs = self.bert(input_ids=input_ids, \n",
    "#                             attention_mask=attention_mask, \n",
    "#                             token_type_ids=token_type_ids\n",
    "#                             )\n",
    "#         pooled_output = outputs.pooler_output  # BERT 的 [CLS] token 表示\n",
    "#         logits = self.classifier(pooled_output)  # 線性層進行分類\n",
    "#         return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import DistilBertModel\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        # 使用 DistilBERT 模型\n",
    "        self.bert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, 8)  # 假設有 8 個分類\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # DistilBERT 輸出 last_hidden_state\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        # 使用 last_hidden_state 的第一個 token 作為句子的表示\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]  # 取 [CLS] token 嵌入\n",
    "        logits = self.classifier(cls_output)  # 線性層進行分類\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BertClassifier().to(device)\n",
    "\n",
    "input_ids = torch.tensor(tokenized_train['input_ids'].numpy()).to(device)\n",
    "attention_mask = torch.tensor(tokenized_train['attention_mask'].numpy()).to(device)\n",
    "# token_type_ids = torch.tensor(tokenized_train['token_type_ids'].numpy()).to(device)\n",
    "\n",
    "train_input = {\n",
    "    'input_ids': input_ids,\n",
    "    'attention_mask': attention_mask,\n",
    "    # 'token_type_ids': token_type_ids,\n",
    "}\n",
    "\n",
    "y_train = torch.tensor(y_train).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62979/62979 [36:18<00:00, 28.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Loss: 1.0975, Accuracy: 0.6032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62979/62979 [36:30<00:00, 28.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "Loss: 0.9498, Accuracy: 0.6572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62979/62979 [36:30<00:00, 28.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5\n",
      "Loss: 0.8409, Accuracy: 0.6970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62979/62979 [36:30<00:00, 28.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n",
      "Loss: 0.7326, Accuracy: 0.7361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62979/62979 [36:33<00:00, 28.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n",
      "Loss: 0.6289, Accuracy: 0.7739\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 16\n",
    "dataset = torch.utils.data.TensorDataset(\n",
    "    train_input['input_ids'], train_input['attention_mask'], y_train\n",
    ")\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for batch in tqdm(dataloader):\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model(input_ids, attention_mask)\n",
    "        \n",
    "        # 計算損失\n",
    "        loss = criterion(logits, labels)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # 計算準確率\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += (preds == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 每個 epoch 結束後，計算平均損失和準確率\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    print(f\"Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    if epoch == 3:\n",
    "        torch.save(model.state_dict(), \"distilbert_classifier_model_epoch_3.pth\")\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), \"distilbert_classifier_model_epoch_5.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"distilbert_classifier_model_epoch_3.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(tokenized_test['input_ids'], tokenized_test['attention_mask'])\n",
    "batch_size = 16\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids = torch.tensor(tokenized_val['input_ids'].numpy()).to(device)\n",
    "# attention_mask = torch.tensor(tokenized_val['attention_mask'].numpy()).to(device)\n",
    "# token_type_ids = torch.tensor(tokenized_val['token_type_ids'].numpy()).to(device)\n",
    "test_ids = torch.tensor(tokenized_test['input_ids'].numpy()).to(device)\n",
    "test_attention_mask = torch.tensor(tokenized_test['attention_mask'].numpy()).to(device)\n",
    "\n",
    "# val_input = {\n",
    "#     'input_ids': input_ids,\n",
    "#     'attention_mask': attention_mask,\n",
    "#     # 'token_type_ids': token_type_ids,\n",
    "# }\n",
    "\n",
    "test_input = {\n",
    "    'input_ids': test_ids,\n",
    "    'attention_mask': test_attention_mask\n",
    "}\n",
    "\n",
    "# y_val = torch.tensor(y_val).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "model.eval()  # 設置模型為評估模式\n",
    "with torch.no_grad():  # 推理時不計算梯度\n",
    "    for batch in tqdm(test_loader):\n",
    "        input_ids, attention_mask = [x.to(device) for x in batch]\n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        probabilities = torch.softmax(logits, dim=-1)\n",
    "        predictions = torch.argmax(probabilities, dim=-1)\n",
    "        class_labels = le.inverse_transform(predictions.cpu())\n",
    "        pred.extend(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['emotion'] = pred\n",
    "submission.to_csv(\"submission_distilbert_epoch_5.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
